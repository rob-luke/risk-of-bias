{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Risk of Bias","text":""},{"location":"#ai-enabled-risk-of-bias-assessment","title":"AI Enabled Risk of Bias Assessment","text":"<p>Risk of bias tools are systematic frameworks primarily used in systematic reviews to evaluate potential flaws in individual studies that could lead to a systematic deviation from the true effect of an intervention.  They aim to identify specific mechanisms through which bias might be introduced into study results, such as problems arising during the study design, conduct, or analysis. This package provides AI and software tools to assist researchers in conducting risk of bias analyses. It can also evaluate draft research protocols before a project commences, helping ensure adherence to best practice and revealing unexpected issues early.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Advanced AI provides robust and independent risk of bias analysis</li> <li>Standard Frameworks such as RoB2 are provided out of the box</li> <li>Batch processing for systematic reviews and meta-analyses (CLI batch analysis)</li> <li>Web interface for single manuscript analysis with download options (web docs)</li> <li>Command line interface for integration into research workflows</li> <li>Latest AI models for evidence extraction and bias assessment</li> <li>RobVis-compatible exports for publication-ready visualisations (visualisation guide)</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#installation","title":"Installation","text":"<p>You can install the program using the following pip command:</p> <pre><code>pip install risk_of_bias[all]\n</code></pre>"},{"location":"#ai-provider","title":"AI Provider","text":"<p>Risk of bias analysis relies on a large language model. Currently only the OpenAI API is supported. After creating an account on OpenAI, export your key before running any commands:</p> <pre><code>export OPENAI_API_KEY=\"sk-...\"\n</code></pre>"},{"location":"#command-line-interface","title":"Command Line Interface","text":"<p>The package comes with an easy to use command line interface (CLI) tool. The CLI tool is installed along with the python package. The CLI tool provides several handy parameters you can adjust. Complete documentation is available in cli</p> <p>But to get started, you can analyse a manuscript by simply passing the path to the file:</p> <pre><code>risk-of-bias analyse /path/to/manuscript.pdf\n</code></pre> <p>You can set the model and parameters. For example, to use a fast and cheap model for testing:</p> <pre><code>risk-of-bias analyse --model gpt-4.1-nano /path/to/manuscript.pdf\n</code></pre> <p>And when you are ready to run a state of the art model, you can switch to a reasoning model. Reasoning models do not use the temperature parameter, so we set it to a negative number to disable it.</p> <pre><code>risk-of-bias analyse --model o3 --temperature -1 /path/to/manuscript.pdf\n</code></pre> <p>For domain-specific assessments or to correct systematic AI biases, you can provide a guidance document. For example, if you are using the RoB2 framework you can include the 72 page additional guidance material. This is achieved using the <code>guidance-document</code> parameter:</p> <pre><code>risk-of-bias analyse /path/to/manuscript.pdf --guidance-document /path/to/guidance.pdf\n</code></pre> <p>The results will be saved next to the pdf as a json, html, and markdown file.</p> <p>The output will look something like:</p> <pre><code>Domain 1: Bias arising from the randomization process.\n\n  Question 1.1: Question 1.1: Was the allocation sequence random? (['Yes', 'Probably Yes', 'Probably No', 'No', 'No Information', 'Not Applicable'])\n    Response: AllowedResponses.Yes\n      Reasoning: The methods section describes the study as a 'randomized crossover study' and states that 'Pairs were then randomized to receive the almond or no-almond (control) interventions.' This indicates that a random allocation sequence was used to assign participants to the initial intervention group. However, the specific method of random sequence generation (e.g., computer-generated random numbers, random number tables) is not described in the provided text.\n        Evidence: A 14-week, randomized crossover study was conducted from January 2014 to May 2014. ... Pairs were then randomized to receive the almond or no-almond (control) interventions and asked to complete daily and weekly questionnaires as well as 3 nonconsecutive, unannounced 24-hour dietary recalls throughout the 3-week intervention.\n\n\n\n  Question 1.2: Question 1.2: Was the allocation sequence concealed until participants were enrolled and assigned to interventions? (['Yes', 'Probably Yes', 'Probably No', 'No', 'No Information', 'Not Applicable'])\n    Response: AllowedResponses.No_Information\n      Reasoning: There is no explicit information in the provided text about how the allocation sequence was concealed from those enrolling participants. The methods do not mention any procedures such as sealed envelopes, central randomization, or other mechanisms to ensure allocation concealment.\n        Evidence: No information is provided in the methods section regarding allocation concealment procedures.\n\n\n\n  Question 1.3: Question 1.3: Did baseline differences between intervention groups suggest a problem with the randomization process? (['Yes', 'Probably Yes', 'Probably No', 'No', 'No Information', 'Not Applicable'])\n    Response: AllowedResponses.No\n      Reasoning: The baseline characteristics table (Table 1) shows demographic and anthropometric data for both parents and children, but since this is a crossover study, each participant serves as their own control, and baseline differences between groups are less relevant. There is no mention of significant baseline imbalances or problems with randomization in the text.\n        Evidence: Table 1 \u2013 Characteristics of 29 child and parent pairs participating in a study examining the effects of almond consumption on dietary quality, gastrointestinal function, inflammation, and immunity ... Most of the parents were non-Hispanic white women, and most children attended a school or daycare outside the home (Table 1).\n\n...\n</code></pre>"},{"location":"#json-data-storage-and-reuse","title":"JSON Data Storage and Reuse","text":"<p>Results are automatically saved in JSON format containing the complete assessment data, including raw AI responses, evidence excerpts, and reasoning. This JSON storage serves multiple purposes:</p> <ul> <li>Efficiency: When re-running analysis on directories, previously analyzed files are automatically detected and loaded from JSON, avoiding redundant AI calls</li> <li>Data sharing: JSON files provide a standardized format for sharing complete assessment results with colleagues or across research teams  </li> <li>Reproducibility: Raw response data is preserved, enabling verification and reanalysis of assessments</li> <li>Batch processing: Essential for systematic reviews where hundreds of papers need processing across multiple sessions</li> </ul> <p>To force re-analysis of previously processed files, delete the corresponding JSON files or use the <code>--force</code> flag.</p> <p>For systematic reviews, you can analyse entire directories and automatically generate RobVis-compatible CSV summaries:</p> <pre><code>risk-of-bias analyse /path/to/manuscripts/\n</code></pre> <p>For manual entry of human assessments, you can use the <code>human</code> command to record your own risk of bias evaluations in a standardized format, enabling direct comparison with AI assessments and ensuring reproducible data storage:</p> <pre><code>risk-of-bias human /path/to/manuscript.pdf\n</code></pre> <p>Further details on summarising results are found in the API docs. Instructions for comparing two assessors are detailed in the API docs. The comparison output includes short domain and question labels (e.g., <code>D1</code>, <code>Q1.1</code>) for quick reference.</p>"},{"location":"#web-interface","title":"Web Interface","text":"<p>A simple web interface is provided to analyse a single manuscript. To start the web interface run:</p> <pre><code>risk-of-bias web\n</code></pre> <p>Then open <code>http://127.0.0.1:8000</code> and upload your manuscript.  After processing you will see the report along with links to  download the JSON and Markdown representations.</p>"},{"location":"#standalone-macos-app","title":"Standalone MacOS App","text":"<p>If you prefer a standalone application, a compiled macOS version of the web interface is attached to every release. It processes one PDF at a time. You can download the latest build here. The app is not signed, so you may need to go to Settings - Security - Allow Application.</p>"},{"location":"#frameworks","title":"Frameworks","text":"<p>The Risk of Bias tool currently only supports the RoB 2 framework. However, it is designed to be extensible, please raise an issue if there's another framework you are interested in.  See frameworks and api/frameworks for additional details and context.</p>"},{"location":"#statement-on-the-use-of-ai-in-research","title":"Statement on the Use of AI in Research","text":"<p>AI does not replace human judgment in risk of bias assessment. Instead, these tools should be viewed as powerful assistants, complementing human expertise. The established gold standard, often involving two independent human reviewers and a third for adjudication, remains paramount for rigorous assessment. However, AI can augment this process; for instance, an AI could serve as an additional reviewer alongside human experts, providing a systematically derived perspective, with a human still making the final adjudication. Recognizing that both human reviewers and AI systems can have inherent biases, incorporating an AI perspective can offer a different lens through which to evaluate studies. Moreover, in situations where resource constraints make achieving the full gold standard difficult, AI tools can provide valuable support, helping to elevate the overall consistency and thoroughness of bias assessment as the field progresses towards universally ideal practices.</p>"},{"location":"#references","title":"References","text":"<pre><code>Sterne JAC, Savovi\u0107 J, Page MJ, Elbers RG, Blencowe NS, Boutron I, Cates CJ,\nCheng H-Y,  Corbett MS, Eldridge SM, Hern\u00e1n MA, Hopewell S, Hr\u00f3bjartsson A,\nJunqueira DR, J\u00fcni P, Kirkham JJ, Lasserson T, Li T, McAleenan A, Reeves BC,\nShepperd S, Shrier I, Stewart LA, Tilling K, White IR, Whiting PF, Higgins JPT.\nRoB 2: a revised tool for assessing risk of bias in randomised trials. \nBMJ 2019; 366: l4898.\n</code></pre>"},{"location":"api/","title":"Details & API","text":"<p>The API is comprised of a hierarchical set of types that mirror the structure of risk-of-bias assessment frameworks like RoB2. This design enables systematic evaluation of research manuscripts through structured questioning and evidence-based responses.</p> <ul> <li> <p>Frameworks define the top-level assessment structure containing multiple evaluation domains. In the RoB2 context, a Framework represents the complete \"Risk of Bias 2\" tool for randomized trials. It organises five primary domains and exposes a <code>judgement</code> property that returns the overall score derived from those domains.</p> </li> <li> <p>Domains represent specific categories of bias within a framework. Each domain focuses on a particular aspect of study methodology that could introduce bias. Domains expose a <code>judgement</code> property that computes the final risk rating from the answers provided. For RoB2 the five primary domains are: (1) bias from randomization process, (2) bias from deviations from intended interventions, (3) bias from missing outcome data, (4) bias in outcome measurement and (5) bias in selection of reported results. The \"Overall\" domain captures only the predicted direction of bias.</p> </li> <li> <p>Questions are the specific signaling questions within each domain that guide the assessment process. These questions are designed to systematically evaluate potential sources of bias, with predefined allowed answers (typically \"Yes\", \"Probably Yes\", \"Probably No\", \"No\", \"No Information\", \"Not Applicable\"). But if the user requests no predefined answers (using None), then a string answer will be provided. Questions can be marked as required and are indexed for systematic processing.</p> </li> <li> <p>Responses capture the AI model's assessment for each question, structured as <code>ReasonedResponseWithEvidence</code> objects that include:</p> </li> <li><code>evidence</code>: List of text excerpts from the manuscript that support the assessment</li> <li><code>reasoning</code>: The model's explanation of how the evidence leads to the conclusion</li> <li><code>response</code>: The selected answer from the allowed options, or a self selected string if None is provided for the allowed options.</li> </ul> <p>This hierarchical structure ensures that bias assessments are systematic, traceable, and evidence-based, following established methodological guidelines while leveraging AI capabilities for efficient manuscript analysis.</p>"},{"location":"api/#type-definitions","title":"Type Definitions","text":""},{"location":"api/#framework","title":"Framework","text":""},{"location":"api/#risk_of_bias.types._framework_types.Framework","title":"<code>risk_of_bias.types._framework_types.Framework</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>The top-level container for risk-of-bias assessment frameworks.</p> <p>A Framework represents a complete methodological assessment tool (e.g., RoB2) that systematically evaluates potential sources of bias in research studies. Frameworks organize the assessment process through a hierarchical structure:</p> <p>Framework \u2192 Domains \u2192 Questions \u2192 Responses</p> <p>The Framework serves as both a template (defining the assessment structure) and a container for results (storing responses after manuscript analysis). When a manuscript is analyzed, the AI model works through each question in sequence, populating the response fields with evidence-based assessments.</p> <p>Attributes:</p> Name Type Description <code>domains</code> <code>list[Domain]</code> <p>The assessment domains that comprise this framework. Each domain focuses on a specific category of potential bias.</p> <code>name</code> <code>str</code> <p>A descriptive name for the framework (e.g., \"RoB2 Framework for Randomized Trials\").</p> <code>manuscript</code> <code>(str, optional)</code> <p>The filename (without path) of the manuscript being assessed.</p> <code>assessor</code> <code>str | None</code> <p>The name or identifier of the person or system performing the assessment. This can be useful for tracking who completed the assessment, especially in collaborative environments.</p>"},{"location":"api/#risk_of_bias.types._framework_types.Framework.judgement","title":"<code>judgement</code>  <code>property</code>","text":"<p>Return the overall risk-of-bias judgement for the framework.</p> <p>The judgement corresponds to the highest (worst) domain judgement across all domains except any explicitly named \"Overall\". If any domain judgement is missing, <code>None</code> is returned.</p> <p>Returns:</p> Type Description <code>str | None</code> <p>\"Low\", \"Some concerns\", or \"High\" when all domain judgements are available, otherwise <code>None</code>.</p>"},{"location":"api/#risk_of_bias.types._framework_types.Framework.__str__","title":"<code>__str__()</code>","text":"<p>Provide a comprehensive human-readable representation of the Framework.</p> <p>This method creates a structured text representation that displays the complete assessment framework hierarchy, making it easy to review the framework structure and any completed assessments. The output format is designed for readability and debugging purposes.</p> <p>The string representation includes: - Framework name and overview - Each domain with its index and name - All questions within each domain with their indices and text - Allowed answer options for each question (if defined) - Response details for answered questions, including:   - The selected response   - The reasoning behind the assessment   - Supporting evidence excerpts from the manuscript - Clear indication of unanswered questions</p> <p>Returns:</p> Type Description <code>str</code> <p>A multi-line string representation of the framework showing: - Framework structure (domains and questions) - Assessment progress (which questions have been answered) - Complete response details for answered questions</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; framework = Framework(name=\"RoB2 Framework\")\n&gt;&gt;&gt; print(framework)\nFramework: RoB2 Framework\nDomain 1: Randomization Process\n  Question 1.1: Was the allocation sequence random? (['Yes', 'Probably Yes',\n  ...])\n    Response: Yes\n      Reasoning: The study clearly describes using computer-generated\n      randomization\n        Evidence: \"Participants were randomized using a computer-generated\n        sequence\"\n</code></pre> Notes <p>This method is particularly useful for:</p> <ul> <li>Reviewing framework structure during development</li> <li>Debugging assessment workflows</li> <li>Generating human-readable reports of completed assessments</li> <li>Understanding the hierarchical organization of bias assessment questions</li> </ul>"},{"location":"api/#risk_of_bias.types._framework_types.Framework.export_to_html","title":"<code>export_to_html(path)</code>","text":"<p>Export the framework as an HTML document.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Destination file for the HTML representation.</p> required"},{"location":"api/#risk_of_bias.types._framework_types.Framework.export_to_markdown","title":"<code>export_to_markdown(path)</code>","text":"<p>Export the framework as a Markdown document.</p> <p>This method creates a structured Markdown representation of the framework and its assessment results, suitable for documentation, reporting, or sharing with stakeholders.</p> <p>The generated Markdown includes: - Framework name as the main heading - Each domain as a section with its index and name - Questions within each domain with their indices and text - Allowed answer options for each question - Response details for answered questions, including:   - The selected response   - The reasoning behind the assessment   - Supporting evidence excerpts from the manuscript</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Destination file for the Markdown representation.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; framework = Framework(name=\"RoB2 Framework\")\n&gt;&gt;&gt; framework.export_to_markdown(Path(\"assessment_report.md\"))\n</code></pre>"},{"location":"api/#risk_of_bias.types._framework_types.Framework.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a framework from a JSON file at <code>path</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The file to read from.</p> required <p>Returns:</p> Type Description <code>Framework</code> <p>An instance populated with the data from the file.</p>"},{"location":"api/#risk_of_bias.types._framework_types.Framework.save","title":"<code>save(path)</code>","text":"<p>Save the framework as formatted JSON to <code>path</code>.</p> <p>This method excludes raw_data fields from the JSON output to keep the saved files clean and focused on assessment results.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Location to write the JSON representation.</p> required"},{"location":"api/#pre-built-frameworks","title":"Pre-built Frameworks","text":"<p>The package provides ready-to-use frameworks that implement established risk-of-bias assessment methodologies. These frameworks come pre-configured with all necessary domains, questions, and answer options, allowing you to immediately begin manuscript analysis without manual setup.</p>"},{"location":"api/#rob2-framework","title":"RoB2 Framework","text":""},{"location":"api/#risk_of_bias.frameworks.get_rob2_framework","title":"<code>risk_of_bias.frameworks.get_rob2_framework()</code>","text":"<p>Get the complete RoB2 (Risk of Bias 2) Framework for Randomized Trials.</p> <p>This function returns a fully configured RoB2 framework that implements the Cochrane Risk of Bias tool version 2.0 guidelines for systematic evaluation of bias in randomized controlled trials.</p> <p>The RoB2 framework is the gold standard for assessing risk of bias in randomized trials and is widely used in systematic reviews and meta-analyses. It provides a structured approach to evaluate five key domains where bias commonly occurs in clinical research and includes an additional domain for the overall risk of bias judgement.</p> Framework Structure <p>The framework contains five primary assessment domains, each with specific signaling questions designed to systematically evaluate potential sources of bias. A sixth domain captures the overall risk-of-bias judgement:</p> <p>Domain 1: Bias arising from the randomization process     Evaluates the adequacy of the randomization sequence generation and     allocation concealment mechanisms.</p> <p>Domain 2: Bias due to deviations from intended interventions     Assesses whether there were deviations from intended interventions     and whether the analysis was appropriate.</p> <p>Domain 3: Bias due to missing outcome data     Examines whether outcome data was available for all participants     and whether missingness could depend on the true value.</p> <p>Domain 4: Bias in measurement of the outcome     Evaluates whether the outcome measurement was appropriate and     whether measurement differed between intervention groups.</p> <p>Domain 5: Bias in selection of the reported result     Assesses whether the reported result was selected from multiple     measurements or analyses of the data.</p> <p>Domain 6: Overall risk of bias     Provides the overall judgement for the outcome, including the predicted     direction of bias.</p> <p>Returns:</p> Type Description <code>Framework</code> <p>A configured Framework instance containing the five RoB2 bias domains plus the overall judgement domain, with their respective signaling questions and answer options. The framework is ready for immediate use with <code>run_framework()</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from risk_of_bias.frameworks.rob2 import get_rob2_framework\n&gt;&gt;&gt; from risk_of_bias import run_framework\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Get the pre-configured framework\n&gt;&gt;&gt; framework = get_rob2_framework()\n&gt;&gt;&gt; print(f\"Framework: {framework.name}\")\n&gt;&gt;&gt; print(f\"Number of domains: {len(framework.domains)}\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # Use with manuscript analysis\n&gt;&gt;&gt; manuscript = Path(\"manuscript.pdf\")\n&gt;&gt;&gt; results = run_framework(manuscript=manuscript, framework=framework)\n</code></pre> Notes <p>This framework follows the official RoB2 guidance and includes all standard signaling questions with the appropriate answer options: \"Yes\", \"Probably Yes\", \"Probably No\", \"No\", \"No Information\", \"Not Applicable\".</p> <p>The framework structure mirrors the official RoB2 tool to ensure consistency with established assessment practices in systematic review methodology.</p> References <p>Sterne JAC, Savovi\u0107 J, Page MJ, et al. RoB 2: a revised tool for assessing risk of bias in randomised trials. BMJ 2019; 366: l4898.</p>"},{"location":"api/#executing-a-framework","title":"Executing a framework","text":""},{"location":"api/#risk_of_bias.run_framework","title":"<code>risk_of_bias.run_framework</code>","text":""},{"location":"api/#risk_of_bias.run_framework.run_framework","title":"<code>run_framework(manuscript, framework=get_rob2_framework(), model=settings.fast_ai_model, guidance_document=None, verbose=False, temperature=settings.temperature, api_key=None)</code>","text":"<p>Perform systematic risk-of-bias assessment on a research manuscript using AI.</p> <p>This function automates the process of evaluating potential sources of bias in research studies by systematically working through a structured assessment framework. It combines established methodological frameworks (like RoB2) with AI capabilities to provide evidence-based bias assessments.</p> The Assessment Process <p>The function implements a comprehensive workflow:</p> <ol> <li>Framework Setup: Uses a pre-defined assessment framework containing    organized domains and signaling questions</li> <li>Context Establishment: Sends system instructions to guide the AI model's    assessment approach</li> <li>Guidance Integration: If provided, incorporates domain-specific guidance    document to calibrate AI responses and provide specialized assessment criteria</li> <li>Document Processing: Converts the manuscript PDF to a format the AI can    analyze</li> <li>Systematic Questioning: Sends all questions within a domain in a    single request, reducing the number of API calls while maintaining    conversation context</li> <li>Evidence-Based Responses: For each domain the AI returns a list of    structured answers corresponding to each question. Each item includes:</li> <li>The chosen response from predefined options</li> <li>Detailed reasoning explaining the assessment</li> <li>Specific evidence excerpts from the manuscript</li> <li>Result Integration: Stores all parsed responses back into the framework    structure for easy access and analysis</li> </ol> <p>Parameters:</p> Name Type Description Default <code>manuscript</code> <code>Path</code> <p>Path to the research manuscript PDF file to analyze. The file must exist and be readable. Supported formats include standard academic PDFs.</p> required <code>framework</code> <code>Framework</code> <p>The assessment framework defining the structure of the bias evaluation. Defaults to the complete RoB2 framework for randomized controlled trials. Custom frameworks can be provided for specialized assessments.</p> <code>get_rob2_framework()</code> <code>model</code> <code>str</code> <p>The OpenAI model identifier to use for assessment. Different models may provide varying levels of analysis depth and accuracy. The default is optimized for speed while maintaining quality.</p> <code>settings.fast_ai_model</code> <code>guidance_document</code> <code>Optional[Path]</code> <p>Optional path to a PDF guidance document that provides domain-specific assessment criteria and AI calibration instructions. This feature enables:</p> <ul> <li>Domain-specific expertise: Specialized interpretation criteria for   fields like pediatric studies, surgical interventions, or rare diseases</li> <li>AI bias correction: Systematic adjustments when the AI consistently   misinterprets methodological aspects or shows patterns of being overly   lenient or conservative in specific assessment domains</li> <li>Standardization: Consistent application of journal-specific guidelines   or institutional assessment standards across multiple manuscripts</li> <li>Contextual clarification: Detailed explanations for ambiguous scenarios   that frequently arise in specialized research contexts</li> </ul> <p>The guidance document is presented to the AI before manuscript analysis, ensuring that your specified criteria and calibrations are consistently applied throughout the entire assessment process.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to print detailed progress information during assessment. When True, displays each question, response, reasoning, and evidence in real-time. Useful for debugging, monitoring progress, or understanding the assessment process in detail.</p> <code>False</code> <code>temperature</code> <code>float</code> <p>Sampling temperature passed to the OpenAI model. Higher values yield more diverse answers while lower values make outputs more deterministic. If a negative value is provided, the temperature parameter is omitted and the server default is used.</p> <code>settings.temperature</code> <code>api_key</code> <code>Optional[str]</code> <p>API key to use for OpenAI calls. If <code>None</code>, <code>OPENAI_API_KEY</code> from the environment will be used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Framework</code> <p>The original framework structure populated with AI-generated responses. Each question in the framework will contain a ReasonedResponseWithEvidenceAndRawData object with:</p> <ul> <li>response: The selected answer from the allowed options</li> <li>reasoning: Detailed explanation of the assessment logic</li> <li>evidence: List of relevant text excerpts from the manuscript</li> <li>raw_data: Complete raw response data from the AI model</li> </ul> <p>The populated framework maintains the hierarchical structure (Framework \u2192 Domains \u2192 Questions \u2192 Responses) for easy navigation and analysis of results. This complete data structure can be serialized to JSON format for persistence, caching, and data sharing workflows.</p>"},{"location":"api/#manual-entry","title":"Manual Entry","text":""},{"location":"api/#risk_of_bias.human.run_human_framework","title":"<code>risk_of_bias.human.run_human_framework(manuscript, framework=get_rob2_framework(), console=None)</code>","text":"<p>Interactively complete a risk-of-bias framework.</p> <p>This function guides the user through each question in the framework using a Rich console. Users select or type responses and may provide optional reasoning and evidence. Required questions must be answered; optional questions can be skipped by pressing Enter. Reasoning and evidence prompts can also be skipped with Enter.</p> <p>Parameters:</p> Name Type Description Default <code>manuscript</code> <code>Path</code> <p>Path to the manuscript being assessed. Only the file name is stored in the resulting framework.</p> required <code>framework</code> <code>Framework</code> <p>Framework to populate with user responses.</p> <code>get_rob2_framework()</code> <code>console</code> <code>Console</code> <p>Console instance for input and output. A new one is created if <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Framework</code> <p>The provided framework populated with user responses.</p>"},{"location":"api/#domain","title":"Domain","text":""},{"location":"api/#risk_of_bias.types.Domain","title":"<code>risk_of_bias.types.Domain</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A thematic grouping of related bias assessment questions within a framework.</p> <p>Domains represent the conceptual organization of bias assessment, where each domain focuses on a specific methodological aspect that could introduce bias into research findings. This organizational structure reflects how bias assessment experts think about and categorize different types of threats to study validity.</p> Conceptual Foundation <p>The domain concept stems from decades of methodological research showing that bias in research studies tends to cluster around specific aspects of study design and conduct. Rather than having an unstructured list of questions, domains provide logical groupings that:</p> <ul> <li>Guide Systematic Thinking: Help assessors consider all major categories   of potential bias systematically</li> <li>Enable Targeted Assessment: Allow focus on specific methodological   concerns relevant to different study types</li> <li>Support Hierarchical Analysis: Enable both domain-level and overall   framework-level bias judgments</li> <li>Facilitate Communication: Provide a shared vocabulary for discussing   specific types of bias concerns</li> </ul> Assessment Workflow <p>During assessment, domains are typically evaluated sequentially, with each domain's questions answered before moving to the next. This approach:</p> <ul> <li>Maintains focus on one type of bias at a time</li> <li>Allows for domain-specific reasoning and evidence gathering</li> <li>Enables partial assessments when time or information is limited</li> <li>Supports quality control by domain-expert reviewers</li> </ul> <p>Attributes:</p> Name Type Description <code>questions</code> <code>list[Question]</code> <p>The signaling questions that comprise this domain's assessment. Questions are typically ordered from fundamental to more detailed aspects of the bias type being evaluated.</p> <code>name</code> <code>str</code> <p>A descriptive name for the domain that clearly indicates the type of bias being assessed (e.g., \"Bias arising from the randomization process\").</p> <code>index</code> <code>int</code> <p>The sequential position of this domain within the overall framework. Used for organizing assessment workflow and reporting results in a consistent order.</p>"},{"location":"api/#risk_of_bias.types.Domain.judgement","title":"<code>judgement</code>  <code>property</code>","text":"<p>Return the risk-of-bias judgement for this domain.</p>"},{"location":"api/#question","title":"Question","text":""},{"location":"api/#risk_of_bias.types.Question","title":"<code>risk_of_bias.types.Question</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>An individual signaling question that guides bias assessment within a domain.</p> <p>Questions are the fundamental building blocks of systematic bias assessment, designed to probe specific methodological aspects that could introduce bias into research findings. Each question represents a focused inquiry that helps assessors systematically evaluate study quality and potential threats to validity.</p> Question Types and Response Modes <p>Questions can be configured for different types of assessment needs:</p> <p>Structured Assessment (default): When <code>allowed_answers</code> contains predefined options (like \"Yes\", \"Probably Yes\", \"No\", etc.), the AI must select from these specific choices. This approach:</p> <ul> <li>Ensures consistency across assessments</li> <li>Enables quantitative analysis and meta-analysis</li> <li>Follows established assessment frameworks like RoB2</li> <li>Facilitates automated processing and reporting</li> </ul> <p>Free-Form Assessment: When <code>allowed_answers = None</code>, the AI can provide any string response of arbitrary length. This mode is valuable for:</p> <ul> <li>Exploratory questions requiring detailed explanations</li> <li>Capturing nuanced methodological details</li> <li>Gathering qualitative insights about study design</li> <li>Custom assessment criteria not covered by standard frameworks</li> <li>Collecting recommendations for study improvement</li> </ul> Assessment Context and Evidence <p>Regardless of response mode, each question generates comprehensive assessment data including:</p> <ul> <li>Response: The selected answer (structured) or free-form text</li> <li>Reasoning: Detailed explanation of the assessment logic</li> <li>Evidence: Specific text excerpts from the manuscript supporting the conclusion</li> </ul> <p>This evidence-based approach ensures that assessments are transparent, auditable, and grounded in the actual study documentation.</p> <p>Attributes:</p> Name Type Description <code>question</code> <code>str</code> <p>The text of the signaling question presented to the AI assessor. Should be clear, specific, and answerable based on typical manuscript content. Well-designed questions avoid ambiguity and focus on observable methodological features.</p> <code>allowed_answers</code> <code>list[str] | None</code> <p>Defines the response mode for this question:</p> <ul> <li>List of strings: Restricts responses to predefined options,   ensuring standardized assessment (e.g., [\"Yes\", \"No\", \"Unclear\"])</li> <li>None: Enables free-form text responses of any length,   allowing detailed explanations and custom insights</li> </ul> <p>The default provides standard bias assessment options commonly used in systematic review methodologies.</p> <code>index</code> <code>float, default=0.0</code> <p>The position of this question within its domain, determining assessment order. Float values allow for flexible question insertion (e.g., 1.5 between questions 1 and 2) without renumbering entire sequences.</p> <code>is_required</code> <code>bool, default=False</code> <p>Whether this question must be answered for a complete assessment. Required questions typically address fundamental methodological features essential for bias evaluation, while optional questions may provide additional insights or apply only to specific study types.</p> <code>response</code> <code>ReasonedResponseWithEvidenceAndRawData | None, default=None</code> <p>The AI-generated assessment response, populated during framework execution. Contains the structured response, reasoning, supporting evidence, and raw model output data.</p>"},{"location":"api/#response","title":"Response","text":""},{"location":"api/#risk_of_bias.types.ReasonedResponseWithEvidence","title":"<code>risk_of_bias.types.ReasonedResponseWithEvidence</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A structured response container that captures comprehensive AI assessment data.</p> <p>This class represents the core output of the AI bias assessment process, combining three essential components that make automated assessment both reliable and transparent: the actual response, the reasoning behind it, and the supporting evidence from the manuscript.</p> The Transparency Imperative <p>Traditional bias assessment often involves subjective expert judgment that can be difficult to audit or reproduce. This structured response format addresses these limitations by making the assessment process transparent:</p> <ul> <li>Explicit Reasoning: Every assessment includes detailed explanation   of the logic and criteria used to reach the conclusion</li> <li>Evidence-Based: All conclusions are anchored to specific text   from the manuscript, enabling verification and quality control</li> <li>Reproducible: The structured format allows for consistent review,   comparison, and potential re-evaluation of assessments</li> </ul> Multi-Modal Assessment Support <p>The evidence component is designed to work with various types of supporting information:</p> <ul> <li>Direct Quotes: Exact text excerpts from methodology sections</li> <li>Paraphrased Content: Summarized information when direct quotes   would be too lengthy or fragmented</li> <li>Multi-Source Evidence: Citations from different parts of the   manuscript that collectively support the assessment</li> <li>Contextual Information: Background details that inform the   interpretation of methodological choices</li> </ul> <p>Attributes:</p> Name Type Description <code>evidence</code> <code>list[str]</code> <p>A collection of text excerpts from the manuscript that support the assessment conclusion. Each item should be a meaningful piece of evidence that directly relates to the question being assessed. Evidence items are typically:</p> <ul> <li>Direct quotations from relevant manuscript sections</li> <li>Specific methodological details described by the authors</li> <li>Quantitative information (sample sizes, response rates, etc.)</li> <li>Procedural descriptions that inform bias assessment</li> </ul> <p>Multiple evidence items allow for comprehensive support of complex assessments that may depend on information scattered throughout the manuscript.</p> <code>reasoning</code> <code>str</code> <p>A detailed explanation of the assessment logic connecting the evidence to the conclusion. This should include:</p> <ul> <li>Interpretation of the evidence in methodological context</li> <li>Application of relevant bias assessment criteria</li> <li>Consideration of alternative interpretations</li> <li>Explanation of how the evidence leads to the specific response</li> </ul> <p>High-quality reasoning demonstrates methodological sophistication and provides the rationale needed for assessment validation.</p> <code>response</code> <code>str</code> <p>The actual assessment answer, either selected from predefined options (for structured questions) or provided as free-form text (for open-ended questions). This represents the final conclusion of the assessment process based on the evidence and reasoning.</p>"},{"location":"api/#summary-and-analysis-functions","title":"Summary and Analysis Functions","text":"<p>After completing individual risk-of-bias assessments using frameworks, researchers typically need to analyze results across multiple studies for systematic reviews, meta-analyses, or research synthesis. The summary functions provide essential tools for aggregating, visualizing, and exporting assessment results in formats compatible with established research workflows.</p> <p>These functions address three critical needs in evidence synthesis:</p> <ol> <li>Batch Processing: Loading and processing multiple completed assessments from saved framework files</li> <li>Data Aggregation: Extracting domain-level judgements across studies for comparative analysis  </li> <li>Standardized Export: Creating outputs compatible with specialized visualization tools like RobVis</li> </ol> <p>This workflow supports the transition from individual study assessment to systematic evidence synthesis, enabling researchers to identify patterns of bias across study collections and generate publication-ready visualizations for systematic reviews.</p>"},{"location":"api/#loading-multiple-assessments","title":"Loading Multiple Assessments","text":""},{"location":"api/#risk_of_bias.summary.load_frameworks_from_directory","title":"<code>risk_of_bias.summary.load_frameworks_from_directory(directory)</code>","text":"<p>Load multiple completed risk-of-bias assessments for batch analysis.</p> <p>This function enables systematic reviews and meta-analyses by batch-loading previously completed framework assessments from a directory. After conducting individual risk-of-bias assessments on multiple studies, researchers typically need to analyze patterns across their entire study collection. This function streamlines that process by automatically discovering and loading all completed assessments.</p> <p>The function is fault-tolerant, continuing to load valid frameworks even if some files are corrupted or incompatible. This robustness is essential when working with large collections of assessments that may have been created over time or by different researchers.</p> <p>Common use cases include: - Preparing data for systematic review summary tables - Generating cross-study bias pattern visualizations - Creating inputs for meta-analysis software - Quality assurance checks across assessment batches</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>Path | str</code> <p>Directory containing previously saved framework JSON files from completed risk-of-bias assessments.</p> required <p>Returns:</p> Type Description <code>list[Framework]</code> <p>List of successfully loaded frameworks. Files that cannot be parsed (due to corruption, format changes, etc.) are silently ignored to ensure batch processing continues.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; frameworks = load_frameworks_from_directory(\"./completed_assessments/\")\n&gt;&gt;&gt; print(f\"Loaded {len(frameworks)} completed assessments\")\n</code></pre>"},{"location":"api/#creating-assessment-summaries","title":"Creating Assessment Summaries","text":""},{"location":"api/#risk_of_bias.summary.summarise_frameworks","title":"<code>risk_of_bias.summary.summarise_frameworks(frameworks)</code>","text":"<p>Extract domain-level risk judgements for comparative analysis across studies.</p> <p>This function transforms detailed framework assessments into a simplified summary format suitable for systematic review tables, meta-analysis inputs, and cross-study comparisons. By extracting only the final risk-of-bias judgements for each domain, it creates a standardized view that facilitates pattern recognition and evidence synthesis across multiple studies.</p> <p>The function reads the :pyattr:<code>~risk_of_bias.types._domain_types.Domain.judgement</code> property of each domain. This property dynamically computes the risk judgement based on the domain's current question responses. If a framework does not include a domain explicitly named <code>\"Overall\"</code>, the returned summary will include an <code>\"Overall\"</code> entry computed from the :pyattr:<code>~risk_of_bias.types._framework_types.Framework.judgement</code> property.</p> <p>Key applications include: - Creating summary tables for systematic review publications - Identifying studies with consistent bias patterns across domains - Preparing data for risk-of-bias visualization tools (e.g., RobVis) - Supporting meta-analysis decisions about study inclusion/weighting</p> <p>Parameters:</p> Name Type Description Default <code>frameworks</code> <code>list[Framework]</code> <p>Completed framework assessments to summarise. These should contain domain-level judgements accessible via the :pyattr:<code>~risk_of_bias.types._domain_types.Domain.judgement</code> property.</p> required <p>Returns:</p> Type Description <code>dict[str, dict[str, str | None]]</code> <p>Nested mapping structure where: - Outer keys: manuscript/study identifiers - Inner keys: domain names - Values: risk-of-bias judgements (\"low\", \"some concerns\", \"high\")   or None if no judgement was recorded</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; summary = summarise_frameworks(loaded_frameworks)\n&gt;&gt;&gt; print(summary[\"Smith2023\"][\"Randomization Process\"])\n'low'\n</code></pre>"},{"location":"api/#exporting-for-visualization","title":"Exporting for Visualization","text":""},{"location":"api/#risk_of_bias.summary.export_summary","title":"<code>risk_of_bias.summary.export_summary(summary, path)</code>","text":"<p>Export risk-of-bias summary to a CSV file for analysis and visualization.</p> <p>This function saves the risk-of-bias assessment summary as a CSV (Comma-Separated Values) file, a widely-supported standard format that can be opened in spreadsheet applications like Excel, imported into statistical software like R or Python, or used with specialized risk-of-bias visualization tools.</p> <p>The exported CSV is specifically formatted to be compatible with RobVis, a popular R package and web application for creating publication-ready risk-of-bias visualizations. This ensures seamless interoperability between this tool and the broader risk-of-bias assessment ecosystem. The RobVis tool can generate traffic light plots and summary plots that are commonly used in systematic reviews and meta-analyses.</p> <p>The CSV structure includes: - A <code>Study</code> column containing manuscript/study identifiers - Domain columns (<code>D1</code>, <code>D2</code>, ..., <code>Dn</code>) for each risk-of-bias domain - An <code>Overall</code> column. If a domain named <code>Overall</code> exists in the   summary it will be used directly; otherwise the column represents the   highest (worst) risk rating across all domains</p> <p>Risk judgements are formatted according to RobVis conventions: - \"Low\" for low risk of bias - \"Some concerns\" for moderate risk of bias - \"High\" for high risk of bias</p> <p>Parameters:</p> Name Type Description Default <code>summary</code> <code>Mapping[str, Mapping[str, str | None]]</code> <p>Output from :func:<code>summarise_frameworks</code> containing the risk-of-bias assessments.</p> required <code>path</code> <code>Path | str</code> <p>Destination file path for the CSV export. The file will be created or overwritten.</p> required Notes <p>The exported CSV can be directly uploaded to the RobVis web interface at https://www.riskofbias.info/welcome/robvis-visualization-tool or used with the RobVis R package for programmatic visualization generation.</p>"},{"location":"api/#comparing-assessors","title":"Comparing Assessors","text":""},{"location":"api/#risk_of_bias.compare.compare_frameworks","title":"<code>risk_of_bias.compare.compare_frameworks(fw1, fw2)</code>","text":"<p>Compare two completed risk-of-bias frameworks.</p> <p>Parameters:</p> Name Type Description Default <code>fw1</code> <code>Framework</code> <p>Completed risk-of-bias frameworks to compare. The domain and question structure must be identical between the two frameworks.</p> required <code>fw2</code> <code>Framework</code> <p>Completed risk-of-bias frameworks to compare. The domain and question structure must be identical between the two frameworks.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Long-form table with <code>domain_short</code>, <code>question_short</code>, <code>domain</code>, <code>question</code> and one column per assessor containing their responses. If a question was unanswered, the value will be <code>None</code>. The final column <code>agreement</code> indicates if the assessors provided the same response.</p>"},{"location":"api/#assessor-agreement-plot","title":"Assessor Agreement Plot","text":""},{"location":"api/#risk_of_bias.visualisation.plot_assessor_agreement","title":"<code>risk_of_bias.visualisation.plot_assessor_agreement(df)</code>","text":"<p>Visualise agreement between two assessors.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Table returned by :func:<code>compare_frameworks</code>.</p> required <p>Returns:</p> Type Description <code>Figure</code> <p>Figure with scatter points for each assessor.</p>"},{"location":"cli/","title":"Command Line Interface","text":"<p>The package comes with an easy to use command line interface (CLI) tool. The CLI tool is installed along with the python package.</p>"},{"location":"cli/#command-line-interface","title":"Command Line Interface","text":"<p>The CLI tool provides several handy parameters you can adjust, these can be found using:</p> <pre><code>&gt; risk-of-bias --help\n\n Usage: risk-of-bias [OPTIONS] COMMAND [ARGS]...\n\n Run risk of bias assessment\n\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --install-completion          Install completion for the current shell.        \u2502\n\u2502 --show-completion             Show completion for the current shell, to copy   \u2502\n\u2502                               it or customise the installation.                \u2502\n\u2502 --help                        Show this message and exit.                      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 analyse   Run risk of bias assessment on a manuscript or directory             \u2502\n\u2502 human     Enter risk of bias results manually\n \u2502\n\u2502 web       Launch the web interface using uvicorn.                              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>The <code>analyse</code> command accepts options for model selection and the sampling temperature. Temperature defaults to <code>0.2</code> and controls the randomness of the OpenAI model's responses. If a negative value is supplied the temperature setting is omitted, and the server default is used instead.</p> <p>And you can analyse a manuscript by simply passing the path to the file:</p> <pre><code>risk-of-bias analyse /path/to/manuscript.pdf\n</code></pre>"},{"location":"cli/#risk-of-bias-analysis-on-manuscript-pdf","title":"Risk of Bias Analysis on Manuscript PDF","text":"<p>You can run the same command on a draft protocol prior to starting a study:</p> <pre><code>risk-of-bias analyse /path/to/protocol.pdf\n</code></pre> <p>Assessing protocols in advance helps verify compliance with best-practice guidelines and reveals potential methodological problems before commencement.</p>"},{"location":"cli/#guidance-documents","title":"Guidance Documents","text":"<p>The CLI supports an optional <code>--guidance-document</code> parameter that allows you to provide domain-specific instructions or corrections to the AI assessment process. This feature is particularly valuable when:</p> <ul> <li>Domain-specific expertise is required: For specialized fields like pediatric studies, surgical interventions, or rare diseases where standard risk-of-bias criteria may need contextual interpretation</li> <li>Correcting systematic AI biases: When the AI consistently misinterprets certain methodological aspects or shows patterns of being overly lenient or conservative in specific domains</li> <li>Journal-specific requirements: When conducting assessments according to particular journal guidelines or institutional standards</li> <li>Training consistency: When multiple reviewers need to apply consistent interpretation criteria across a large systematic review</li> </ul>"},{"location":"cli/#usage","title":"Usage","text":"<pre><code>risk-of-bias analyse manuscript.pdf --guidance-document domain_guidance.pdf\n</code></pre>"},{"location":"cli/#creating-effective-guidance-documents","title":"Creating Effective Guidance Documents","text":"<p>A guidance document should be a PDF containing:</p> <ol> <li>Specific interpretation criteria for ambiguous scenarios</li> <li>Domain-specific examples of how to classify common situations</li> <li>Clarifications on borderline cases that frequently arise in your field</li> <li>Calibration instructions if the AI is systematically too strict or lenient</li> </ol> <p>For example, a guidance document for surgical studies might specify how to interpret blinding when complete blinding is impossible, or provide criteria for assessing outcome measurement bias in subjective surgical outcomes.</p> <p>The guidance document is provided to the AI before manuscript analysis, ensuring consistent application of your specified criteria throughout the assessment process.</p>"},{"location":"cli/#batch-analysis","title":"Batch Analysis","text":"<p>You can analyse an entire directory of manuscripts for systematic reviews and meta-analyses:</p> <pre><code>risk-of-bias analyse /path/to/manuscripts/\n</code></pre> <p>When processing multiple manuscripts, the tool automatically generates a RobVis-compatible CSV summary file containing domain-level risk-of-bias judgements across all studies. This CSV can be directly imported into the RobVis visualization tool or used with statistical software for further analysis.</p>"},{"location":"cli/#manualhuman-entry","title":"Manual/Human Entry","text":"<p>This tool can also be used to enter and store human risk of bias assessments in a standard reproducible file format. This is useful for sharing and storage of results, but also for enabling automatic comparison to the AI risk of bias assessment.</p> <p>If you prefer to record answers yourself, use the <code>human</code> command:</p> <pre><code>risk-of-bias human /path/to/manuscript.pdf\n</code></pre>"},{"location":"cli/#json-data-storage-and-caching","title":"JSON Data Storage and Caching","text":"<p>The tool automatically saves complete assessment results in JSON format alongside each analyzed manuscript. This JSON storage system provides several key benefits:</p>"},{"location":"cli/#automatic-caching-and-reuse","title":"Automatic Caching and Reuse","text":"<pre><code># First run - analyzes manuscript.pdf and saves manuscript.json\nrisk-of-bias analyse manuscript.pdf\n\n# Second run - automatically loads from manuscript.json (no AI call needed)\nrisk-of-bias analyse manuscript.pdf\n</code></pre> <p>When re-running analysis on files or directories, the tool automatically detects existing JSON files and loads previous results instead of re-processing. This is particularly valuable for:</p> <ul> <li>Large systematic reviews: Process hundreds of papers across multiple sessions without redundant analysis</li> <li>Iterative workflows: Make adjustments to post-processing or visualization without re-running expensive AI analysis</li> <li>Cost optimization: Avoid unnecessary OpenAI API calls when refining batch processing workflows</li> </ul>"},{"location":"cli/#forcing-reanalysis","title":"Forcing Reanalysis","text":"<p>To re-analyze previously processed files (e.g., after model updates or methodology changes):</p> <pre><code># Delete JSON files manually\nrm *.json\n\n# Or use the --force flag\nrisk-of-bias analyse manuscript.pdf --force\n</code></pre>"},{"location":"cli/#data-sharing-and-reproducibility","title":"Data Sharing and Reproducibility","text":"<p>JSON files contain the complete assessment data structure including:</p> <ul> <li>All question responses with confidence levels</li> <li>Detailed reasoning for each assessment decision  </li> <li>Specific evidence excerpts from the manuscript text</li> <li>Raw AI model responses for verification</li> <li>Metadata including model version and assessment parameters</li> </ul> <p>This comprehensive data format enables:</p> <ul> <li>Research collaboration: Share complete assessment datasets with team members</li> <li>Methodology verification: Independent review of AI reasoning and evidence selection</li> <li>Standards compliance: Meet journal requirements for transparent bias assessment documentation</li> <li>Meta-analysis integration: Programmatic access to assessment data for statistical analysis</li> </ul> <p>For complete details on the summary functions, data formats, and programmatic access to batch analysis features, see the API documentation.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#simple-development-workflow","title":"Simple Development Workflow","text":"<p>Install app requirements including the optional development packages.</p> <p><code>pip install -e \".[dev]\"</code></p> <p>Ensure the linting and tests pass without issue before you begin development.</p> <ul> <li><code>make lint-check</code></li> <li><code>make test</code></li> </ul> <p>Now make your code changes. Update tests.</p> <p>Ensure you haven't broken any tests or linting.</p> <ul> <li><code>make lint</code></li> <li><code>make test</code></li> </ul> <p>Commit your code.</p> <ul> <li><code>git add -A</code></li> <li><code>git commit -m \"feat: added a new feature\"</code></li> </ul> <p>Push to a new branch and open a pull request.</p>"},{"location":"contributing/#tools-utilised","title":"Tools Utilised","text":""},{"location":"contributing/#standards","title":"Standards","text":"<p>To ensure efficient collaborative development, a variety of standards are utilised in this project.</p> <ul> <li>Semantic Versioning is used.<ul> <li>Python Semantic Releases    is used to automate change log generation and releases.</li> </ul> </li> <li>Conventional Commits are utilised     and validated using the wagoid/commitlint-github-action     github action, which itself uses commitlint<ul> <li>Conventional Commits are also utilised for     pull request titles and enforced using     amannn/action-semantic-pull-request.</li> </ul> </li> <li>Black code formatter is used.<ul> <li>Actions Black    is used to format code in PRs.</li> </ul> </li> <li>Numpy style documentation strings    are used.<ul> <li>Pydocstyle is used to ensure documentation    strings adhere to the standard.</li> </ul> </li> <li>Type hinting is used.<ul> <li>And checked using mypy.</li> </ul> </li> <li>Spelling is enforced using codespell.</li> </ul>"},{"location":"contributing/#website","title":"Website","text":"<ul> <li>The website and documentation is generated by mkdocs   with the mkdocsstrings   extension and material   theme.</li> </ul>"},{"location":"frameworks/","title":"Frameworks","text":""},{"location":"frameworks/#frameworks","title":"Frameworks","text":"<p>The Risk of Bias tool currently only supports the RoB 2 framework. However, it is designed to be extensible, please raise an issue if there's another framework you are interested in. </p>"},{"location":"frameworks/#randomised-trials","title":"Randomised Trials","text":""},{"location":"frameworks/#rob2","title":"RoB2","text":"<p>The RoB 2: a revised tool for assessing risk of bias in randomised trials tool is implemented.</p> <pre><code>Sterne JAC, Savovi\u0107 J, Page MJ, Elbers RG, Blencowe NS, Boutron I, Cates CJ,\nCheng H-Y,  Corbett MS, Eldridge SM, Hern\u00e1n MA, Hopewell S, Hr\u00f3bjartsson A,\nJunqueira DR, J\u00fcni P, Kirkham JJ, Lasserson T, Li T, McAleenan A, Reeves BC,\nShepperd S, Shrier I, Stewart LA, Tilling K, White IR, Whiting PF, Higgins JPT.\nRoB 2: a revised tool for assessing risk of bias in randomised trials. \nBMJ 2019; 366: l4898.\n</code></pre> <p>The following material was used in the preparation of this package:</p> <ul> <li>Cochrane Methods</li> <li>riskofbias.info</li> <li>riskofbias.info RoB2</li> <li>riskofbias.info RoB2 Guidance</li> <li>riskofbias.info RoB2 Cribsheet</li> <li>riskofbias.info RoB2 Template</li> </ul>"},{"location":"mac_app/","title":"macOS Standalone Application","text":"<p>A simple script is provided to create a standalone macOS application using PyInstaller. The generated application bundles the <code>risk_of_bias</code> web interface so it can be run without a Python interpreter.</p>"},{"location":"mac_app/#building","title":"Building","text":"<p>First install the optional development dependencies, which include PyInstaller:</p> <pre><code>pip install \"risk_of_bias[all]\"\n</code></pre> <p>Then run the build script:</p> <pre><code>make mac\n</code></pre> <p>The resulting application can be found in the <code>dist</code> directory. It should launch the web app after a few seconds when run.</p>"},{"location":"mac_app/#github-release-builds","title":"GitHub Release Builds","text":"<p>Each time a release is created on GitHub, an automated workflow runs <code>make mac</code> on a macOS runner and attaches the resulting application to the release. The pre-built download can be found in the release assets. The application bundles the web interface and processes a single PDF at a time. You can always download the most recent version from the latest release.</p>"},{"location":"reporting_and_reproducibility/","title":"Reporting &amp; Reproducibility","text":""},{"location":"reporting_and_reproducibility/#reporting","title":"Reporting","text":"<p>One of the strengths of utilising this package is you can easily report how you reached your results. Record the software version and include the saved framework file with the questions and responses. This single file can be shared alongside your other reproducibility documents to demonstrate exactly how the analysis was performed.</p>"},{"location":"reporting_and_reproducibility/#reproducibility","title":"Reproducibility","text":"<p>Anyone else can run the same query with the same parameters to replicate your process. Large language models are not deterministic, so the identical query may not always produce identical answers. Nonetheless, being able to rerun the analysis with unchanged settings brings us closer to true reproducibility.</p>"},{"location":"visualisation/","title":"Visualisation","text":"<p>There's no need to reinvent the wheel when it comes to figures. We recommend using robvis to create plots from risk-of-bias data. Our export functions generate files that robvis can read directly. See the exporting for visualisation section of the API docs for details.</p>"},{"location":"visualisation/#comparing-assessors","title":"Comparing Assessors","text":"<p>For a quick look at agreement between two assessors you can create a simple scatter plot using <code>plot_assessor_agreement</code>. This displays each question along the x-axis and the response categories on the y-axis, with marker colours indicating agreement (black=agree, red=disagree). Here is an example output:</p> <p></p>"},{"location":"web/","title":"Web Interface","text":"<p>A simple web front end is provided using FastAPI. It lets you upload a PDF and view the standard RoB2 HTML report directly in your browser.</p> <p></p>"},{"location":"web/#running-the-server","title":"Running the server","text":"<p>Install the optional dependencies and start the server with <code>risk-of-bias web</code> (equivalent to <code>make web</code>):</p> <pre><code>pip install \"risk_of_bias[web]\"\nrisk-of-bias web\n</code></pre> <p>Open <code>http://127.0.0.1:8000</code> and upload your manuscript. After processing you will see the report along with links to download the JSON and Markdown representations.</p> <p>If the <code>OPENAI_API_KEY</code> environment variable is not set when the server starts, the upload form will include a field to provide it. When supplied, the key is used for that analysis session.</p> <p>A standalone macOS application based on this interface is generated for each release. It only processes one PDF at a time and can be downloaded from the latest release.</p>"}]}